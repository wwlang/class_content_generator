# Week 2: Career Skills in the AI Era

## Lecture Content (90 minutes)

---

<slide number="1" layout="title" title="Career Skills in the AI Era">
Week 2: Career Skills in the AI Era

Personal & Professional Development
National Economics University, IBD Campus

<speaker-notes>
Welcome to Week 2. Last week we established the five foundational future skills—critical thinking, creativity, emotional intelligence, adaptability, and communication. Today we move from theory to practice: how do you actually use these skills in an AI-transformed workplace? This lecture addresses the most urgent question business students face in 2025: what do I need to learn RIGHT NOW to remain competitive when AI can write reports, analyze data, and generate presentations in seconds?
</speaker-notes>
</slide>

---

<slide number="2" layout="content" title="The Moment Everything Changed">
**October 2025: Fortune Most Powerful Women Summit**

A panel of executives from Microsoft, Workday, and Guild shared a surprising admission:

"Human in the loop is not enough anymore."

**The New Reality:**
- Having a human check AI output is insufficient
- Workers must develop JUDGMENT—not just oversight
- AI changes what employers value in candidates

**Discussion Question:** If AI can do the routine work, what makes YOU valuable?

<speaker-notes>
This is a pivotal moment in business education. For years, we told students "human in the loop" was enough—humans would supervise AI systems and catch errors. But executives at the October 2025 Fortune Summit made clear this is no longer sufficient. Aashna Kircher from Workday stated: "I don't think we are thoughtfully enough educating people about how to be good at judgment. That's a step we will have to take as a civilization in the next three to five years." This lecture prepares you for that civilization-level shift. The question isn't whether you'll work with AI—you will. The question is whether you'll be a strategic director of AI or someone AI makes obsolete.
</speaker-notes>
</slide>

---

<slide number="3" layout="content" title="Today's Learning Objectives">
By the end of this lecture, you will be able to:

1. **Apply** context engineering principles to direct AI effectively in professional tasks
2. **Distinguish** between effective AI collaboration (pilot mindset) and passive AI dependence (passenger mindset)
3. **Identify** AI-generated "workslop" and articulate its professional reputation risks
4. **Evaluate** when human judgment should override AI recommendations
5. **Use** the Explore-Build-Connect-Refine framework for AI-assisted career preparation

<speaker-notes>
These objectives are deliberately action-oriented. You won't just KNOW about context engineering—you'll APPLY it. You won't just understand workslop conceptually—you'll be able to IDENTIFY it in real materials and avoid creating it yourself. Notice how these objectives build on Week 1's foundation: context engineering requires critical thinking; the pilot mindset requires adaptability; workslop awareness requires communication skills. Everything connects.
</speaker-notes>
</slide>

---

<slide number="4" layout="content" title="Connection to Your Assessment">
**Assessment 1 (Week 4): Personal Future Skills Plan**

Today's frameworks directly support your first assessment:
- **Context engineering** → How you'll use AI tools for career research and skill development
- **Pilot vs. Passenger mindset** → Demonstrating strategic thinking in your plan
- **Judgment skills** → Evaluating which skills are genuinely needed vs. trendy
- **Workslop awareness** → Ensuring your submission reflects authentic thinking

**Tutorial This Week:** Hands-on practice using GenAI for personal branding—you'll apply every framework from today's lecture to create application materials that demonstrate judgment, not just AI competence.

<speaker-notes>
Your Assessment 1 is a Personal Future Skills Plan due Week 4. The rubric evaluates whether you demonstrate "strategic synthesis"—not just listing skills, but showing HOW you'll develop them and WHY they matter for your specific career goals. Today's lecture gives you the frameworks to accomplish this. If you submit an AI-generated plan that lacks judgment and reads like "workslop," you'll score poorly even if grammatically perfect. The assessment requires demonstrating the pilot mindset—using AI as a thought partner while maintaining your strategic direction. We'll practice this extensively in tutorial.
</speaker-notes>
</slide>

---

<slide number="5" layout="content" title="Lecture Roadmap">
**Part 1: The New Skill—Context Engineering (20 min)**
- From prompt engineering to context engineering
- Three foundational principles
- Immediate career applications

**Part 2: The Human Advantage—Judgment (20 min)**
- Why "human in the loop" isn't enough
- The pilot vs. passenger mindset
- What executives actually want

**Part 3: The Hidden Risk—Workslop (20 min)**
- AI's productivity paradox
- Professional reputation damage
- The 30-second test

**Part 4: The Practical Framework—Career Preparation (20 min)**
- Explore-Build-Connect-Refine
- AI-assisted CVs, cover letters, interviews
- Verification and authenticity

<speaker-notes>
This lecture is structured around four major insights from cutting-edge 2025 research. Notice the progression: we start with the technical skill (context engineering), add the strategic layer (judgment), introduce the critical risk awareness (workslop), and conclude with immediately actionable frameworks (career preparation). Each segment includes mini-activities and discussion questions—this is NOT a passive lecture. Expect to engage, debate, and apply concepts throughout. The roadmap follows a learning arc from "what is this new skill?" to "how do I use it RIGHT NOW?"
</speaker-notes>
</slide>

---

<slide number="6" layout="section-break" title="Part 1: Context Engineering">
Part 1

Context Engineering:
The Premium Skill Replacing Prompt Engineering

<speaker-notes>
Let's begin with the most important technical skill you can develop in 2025: context engineering. This term was coined by Andrej Karpathy in June 2025—he's the former director of AI at Tesla and one of the most respected voices in the AI industry. Karpathy argued that "prompt engineering" is an outdated term because it makes people think of short task descriptions, when the real skill is filling AI's context window with exactly the right information. Today we'll explore why context engineering is the premium skill employers seek, and how you can start developing it immediately.
</speaker-notes>
</slide>

---

<slide number="7" layout="content" title="What Is Context Engineering?">
**Old Paradigm: Prompt Engineering (2023-2024)**
- Writing clever instructions for AI
- Focus: "How do I phrase this request?"
- Skill: Crafting the perfect command

**New Paradigm: Context Engineering (2025+)**
- Curating what AI "sees" before it responds
- Focus: "What information does AI need?"
- Skill: Strategic information selection

**Why the Shift?**
Modern AI models (like Claude 3.7, GPT-4.5, Gemini 2.0) can follow instructions brilliantly—but they need the RIGHT CONTEXT to produce valuable work.

**Andrej Karpathy (June 2025):** "Context engineering is the delicate art and science of filling the context window with just the right information."

<speaker-notes>
Think of the difference this way: prompt engineering is like telling a brilliant research assistant "write me a market analysis report." Context engineering is providing that assistant with your company's strategic priorities, current market data, competitor intelligence, and your executive team's concerns—THEN asking for the report. The AI's capabilities haven't changed; what's changed is our understanding that providing strategic context produces exponentially better results. Anthropic's research (Rajasekaran et al., 2025) shows that context engineering is now the defining skill separating effective AI users from ineffective ones.
</speaker-notes>
</slide>

---

<slide number="8" layout="framework" title="Framework 1: The Goldilocks Zone">
**Finding the Optimal "Altitude" for Your Instructions**

```
TOO RIGID (Brittle)
"Use exactly 3 bullet points, 12 words each, starting with action verbs..."
↓
❌ Breaks when situation requires flexibility

GOLDILOCKS ZONE (Just Right)
"Summarize key points clearly, using bullet points where appropriate..."
↓
✓ AI adapts to context while following intent

TOO VAGUE (Unpredictable)
"Make it good..."
↓
❌ AI must guess what you want
```

**The Principle:** Instructions should guide behavior without over-specifying format.

<speaker-notes>
The Goldilocks Zone principle comes from Anthropic's engineering blog (September 2025). Engineers discovered that overly rigid instructions create "brittle" AI behavior—the system works perfectly for one scenario but fails completely when conditions change slightly. Overly vague instructions produce unpredictable outputs because AI must guess your intent. The sweet spot is providing clear strategic direction while allowing AI to adapt its approach. Example: If you're drafting a cover letter, DON'T say "Use exactly 4 paragraphs of 3 sentences each." DO say "Explain why I'm interested in this role, highlighting my most relevant experience, and suggest a clear next step." This gives AI strategic direction while allowing it to adapt to the specific content.
</speaker-notes>
</slide>

---

<slide number="9" layout="framework" title="Framework 2: Minimum Effective Dose">
**Less Information, Better Results**

**The Principle:**
"Find the smallest possible set of high-signal tokens that maximize the likelihood of some desired outcome."

**Why This Matters:**
- More information ≠ Better outputs
- Strategic selection beats comprehensive data dumps
- Forces YOU to think critically about what matters

**Career Application Example:**
❌ **Bad:** Paste entire job description + your full CV → "Write cover letter"
✓ **Good:** Identify 3 key job requirements + your 2 most relevant experiences → "Connect these qualifications to these requirements"

**Discussion:** Why would MORE information sometimes produce WORSE results?

<speaker-notes>
This is counterintuitive for students who grew up believing "more information is always better." But AI has finite attention—think of it like your own working memory. If I give you 50 facts before asking a question, you'll struggle to identify which facts matter. Same with AI. The minimum effective dose principle forces you to exercise judgment: What information is genuinely relevant? What's just noise? When you're writing a cover letter, the AI doesn't need to know about every job you've ever held—it needs the 2-3 experiences that directly connect to THIS opportunity. This principle develops your critical thinking because YOU must decide what's signal vs. noise. Passengers dump everything into AI and hope it figures it out. Pilots curate strategically.
</speaker-notes>
</slide>

---

<slide number="10" layout="framework" title="Framework 3: The Attention Budget">
**Context as a Finite, Precious Resource**

**The Metaphor:**
AI's attention is like a spotlight—it illuminates everything in its beam, but the larger the area, the dimmer the light on any single object.

**Technical Reality:**
- Large Language Models have context windows (e.g., 200,000 tokens)
- But attention "stretches thin" across large contexts
- Important details can get lost in information overload

**Strategic Implication:**
Treat AI's context window like your bank account—spend carefully on high-value information.

**Mini-Activity:** Look at your phone's most recent message to someone. If you had to cut 50% of the words while keeping the meaning, which words would you keep? That's attention budget thinking.

<speaker-notes>
This framework comes from research on how Large Language Models actually process information. The technical term is "attention mechanism"—AI doesn't read sequentially like humans do; it calculates relationships between all tokens simultaneously. But there's a mathematical constraint: the more tokens in context, the less "attention weight" each token receives. Imagine your brain trying to focus on 50 conversations at once—you'd catch fragments of each but master none. Same principle. The attention budget framework teaches you to be ruthlessly selective. Before adding information to AI's context, ask: "Does this materially improve the output, or am I just hedging because I'm unsure what matters?" This is judgment in action. In tutorial, you'll practice applying attention budgets to real career preparation tasks—cover letters, networking messages, interview preparation.
</speaker-notes>
</slide>

---

<slide number="11" layout="content" title="Context Engineering in Action: CV Writing">
**Scenario:** You're applying for a marketing analyst role. The job emphasizes "data-driven storytelling."

**Passenger Approach (Weak Context Engineering):**
```
"Here's my CV. Improve it."
[Pastes entire CV with 8 years of unrelated experience]
```
Result: Generic improvements, no strategic focus

**Pilot Approach (Strong Context Engineering):**
```
Context: "This role requires data-driven storytelling. Here are 3 projects where I translated data insights into compelling narratives: [specific examples]. The job description emphasizes Tableau skills and A/B testing experience."

Request: "Help me reorganize my CV to lead with data storytelling skills, emphasizing these 3 projects. Suggest metrics to quantify impact."
```
Result: Strategically tailored CV highlighting relevant strengths

<speaker-notes>
This side-by-side comparison shows context engineering in practice. The passenger approach treats AI like a magic fix-it tool—dump in a CV, hope for improvement. But AI can't read minds; it doesn't know which experiences matter most or what this specific employer values. The pilot approach curates context: "Here's what this employer cares about (data storytelling), here's where I demonstrate that skill (3 projects), now help me emphasize this strategically." Notice the pilot is doing the hard thinking—identifying relevant experience, analyzing job requirements—and using AI to amplify that thinking. You'll practice this exact skill in tutorial when drafting your own career materials.
</speaker-notes>
</slide>

---

<slide number="12" layout="quote" title="The Industry Perspective">
"People associate prompts with short task descriptions... When in every industrial-strength LLM app, context engineering is the delicate art and science of filling the context window with just the right information."

— Andrej Karpathy
Former Director of AI, Tesla
June 2025

<speaker-notes>
Karpathy's endorsement of "context engineering" over "prompt engineering" represents a fundamental shift in how AI professionals think about working with Large Language Models. He's saying: stop thinking about one-off clever prompts. Start thinking about systematic context curation. In industrial applications—the real business uses of AI—success comes from engineering comprehensive context that includes business rules, historical data, strategic priorities, and domain expertise. Then the "prompt" itself can be simple. For your careers, this means: develop the habit of thinking "what context does this system need?" before thinking "what should I tell it to do?" That habit will make you vastly more effective with any AI tool in any role.
</speaker-notes>
</slide>

---

<slide number="13" layout="content" title="Key Takeaway: Context Engineering">
**What You Should Remember:**

1. Context engineering is about **curating** what AI sees, not just what you tell it to do
2. Three core principles:
   - **Goldilocks Zone**: Not too rigid, not too vague
   - **Minimum Effective Dose**: Strategic selection over information dumps
   - **Attention Budget**: Context is finite and precious
3. This skill separates **pilots** (strategic users) from **passengers** (passive users)
4. Immediate application: Every time you use AI, ask yourself: "What context would help AI give me the best possible response?"

**In tutorial:** You'll practice context engineering on your own career materials.

<speaker-notes>
These three principles—Goldilocks Zone, Minimum Effective Dose, Attention Budget—form the foundation of effective AI collaboration. They're not just abstract concepts; they're practical tools you can apply immediately. Before we move to the next segment on judgment, take a moment to reflect: When was the last time you used AI? Did you think about context engineering, or did you just write a quick prompt and hope for the best? Most people do the latter. After today, you'll be equipped to do the former—and that difference will compound over your entire career.
</speaker-notes>
</slide>

---

<slide number="14" layout="section-break" title="Part 2: Human Judgment">
Part 2

Human Judgment:
Why "Human in the Loop" Is No Longer Enough

<speaker-notes>
Now we transition from the technical skill (context engineering) to the strategic capability (judgment). You can be brilliant at context engineering—providing perfect context, getting excellent AI outputs—but if you lack judgment about WHEN to use AI, WHAT outputs to trust, and HOW to integrate AI into your work, you'll still fail. This segment explores why executives at Microsoft, Workday, and Guild all emphasized the same urgent message in October 2025: judgment is now the scarcest, most valuable skill in the AI era.
</speaker-notes>
</slide>

---

<slide number="15" layout="content" title="The Judgment Crisis: What Executives Are Saying">
**Fortune Most Powerful Women Summit, October 2025**

**Aashna Kircher (Workday, Chief Innovation Officer):**
"I don't think we are thoughtfully enough educating people about how to be good at judgment. That's a step we will have to take as a civilization, honestly, in the next three to five years."

**Katy George (Microsoft, Chief People Officer):**
Employees who thrive will demonstrate:
- Sound judgment in ambiguous situations
- Ability to delegate effectively to AI agents
- Quality control over AI outputs
- Design-thinking mindset for complex problems

**The Urgent Question:** If AI can analyze data and generate recommendations instantly, what does HUMAN judgment actually mean?

<speaker-notes>
These are not academic researchers making theoretical predictions. These are chief officers at major global corporations—Microsoft, Workday—telling us in October 2025 what they're seeing RIGHT NOW in their hiring and performance evaluations. Kircher's statement is particularly striking: "That's a step we will have to take as a civilization." She's saying our education systems are not currently producing graduates who can exercise sound judgment, and this is a societal emergency. George's list is your hiring criteria checklist—sound judgment, effective delegation to AI, quality control, design thinking. If you develop these capabilities, you're employable. If you don't, you're competing with AI for commoditized work. The stakes are that clear.
</speaker-notes>
</slide>

---

<slide number="16" layout="content" title="Beyond Human in the Loop: The Three Levels">
**Level 1: Human in the Loop (2023-2024 Standard)**
- AI generates outputs
- Human reviews and approves
- Good enough for routine tasks

**Level 2: Human at the Helm (Current Expectation)**
- Human sets strategic direction BEFORE AI involvement
- AI executes tactical work
- Human evaluates alignment with strategic intent

**Level 3: Judgment Integration (Premium Skill)**
- Human brings domain expertise, contextual awareness, ethical reasoning
- AI brings data processing, pattern recognition, speed
- Synthesis creates insights neither could achieve alone

**Discussion:** Think of a recent decision you made. How would AI have approached it differently? What human factors did you consider that AI couldn't?

<speaker-notes>
This three-level progression shows how expectations have evolved. Level 1 (human in the loop) was sufficient when AI was less capable—checking for obvious errors was enough. But modern AI is too sophisticated for simple oversight. Level 2 (human at the helm) means you're steering, not just supervising. You decide WHAT work needs to be done, WHY it matters, and WHAT success looks like—AI handles the execution. Level 3 (judgment integration) is the aspirational state where human and AI capabilities truly complement each other. You're not just using AI as a tool; you're creating a collaborative system where your judgment guides AI's capabilities toward outcomes neither could achieve independently. In your careers, you'll operate at all three levels depending on the task. Routine work? Level 1. Strategic projects? Level 3.
</speaker-notes>
</slide>

---

<slide number="17" layout="framework" title="Framework 4: The Pilot vs. Passenger Mindset">
**Two Ways to Work with AI**

**PASSENGER MINDSET:**
- Leans on AI to avoid hard thinking
- Treats AI as answer generator
- Produces outputs that "look polished but ring hollow"
- Abdicates responsibility for quality
- **Result:** Work lacks authenticity and strategic insight

**PILOT MINDSET:**
- Uses AI as thought partner, not answer machine
- Actively steers AI with judgment and framing
- Treats AI outputs as starting points for refinement
- Takes responsibility for final deliverable quality
- **Result:** Work demonstrates human judgment augmented by AI capability

**Critical Question:** When you last used AI for an assignment, were you a pilot or a passenger?

<speaker-notes>
This framework comes from Stanford and BetterUp Labs research published in Harvard Business Review (September 2025). The researchers studied thousands of workers using AI and found a clear bifurcation: pilots are getting promoted and gaining influence; passengers are being marginalized or replaced. The difference? Pilots use AI to amplify their thinking. Passengers use AI to replace their thinking. Here's the uncomfortable truth: being a passenger is easier and faster in the short term. You can generate a report in minutes without thinking deeply. But that report will lack strategic insight, contextual nuance, and authentic voice—and your colleagues will notice. In Vietnamese business culture, where relationships and trust matter enormously, being labeled a "passenger" who produces hollow work is career poison. Be a pilot.
</speaker-notes>
</slide>

---

<slide number="18" layout="content" title="Judgment in Action: The Case Method">
**Scenario:** Your company is considering whether to expand into a new market. AI provides:
- Market size projections
- Competitor analysis
- Risk assessment scores
- Financial modeling

**Questions Only Human Judgment Can Answer:**
1. Does this align with our company's **values** and long-term **vision**?
2. What **relationships** and **cultural dynamics** might affect success?
3. Is the **timing** right given current organizational capacity?
4. What **unintended consequences** might emerge that data doesn't reveal?
5. Would I feel proud explaining this decision to our stakeholders in 5 years?

**Key Insight:** AI can process infinite data. Humans must decide what matters and why.

<speaker-notes>
This case illustrates why judgment can't be automated. AI can tell you a market is profitable, competitors are weak, and financial models look good—but it cannot tell you whether this expansion aligns with your company's identity, whether your team has the cultural competence to operate in that market, or whether you'll look back in 5 years and feel proud of the decision. These are fundamentally human questions requiring emotional intelligence, ethical reasoning, and contextual awareness. Notice how Week 1's future skills become operational here: critical thinking (analyzing unintended consequences), emotional intelligence (considering stakeholder relationships), adaptability (assessing organizational capacity). Judgment is not a single skill—it's the synthesis of multiple capabilities applied to consequential decisions.
</speaker-notes>
</slide>

---

<slide number="19" layout="content" title="Developing Judgment: The Chief Experimentation Officer Mindset">
**Katy George (Microsoft):** Every manager must become a "Chief Experimentation Officer"

**What This Means:**
- **Continuous experimentation:** Test AI tools, iterate, adapt
- **Comfort with ambiguity:** No fixed playbook for AI integration
- **Learning from failure:** Not every AI experiment succeeds
- **Systematic reflection:** What worked? What didn't? Why?

**How to Start NOW:**
1. **Try → Reflect → Adjust:** Use AI for a task, evaluate the result, change your approach
2. **Compare:** Do the same task with and without AI. What differences do you notice?
3. **Track:** Keep a log of AI successes and failures. Patterns will emerge.
4. **Discuss:** Talk with peers about their AI experiences. Learn from diverse approaches.

<speaker-notes>
This is one of the most actionable insights from the Fortune Summit. George is saying: don't wait for AI best practices to be established. Experiment now, learn from what works, adapt your approach. The "Chief Experimentation Officer" mindset means you're constantly testing, measuring, and refining how you use AI. This is deeply connected to Week 1's adaptability skill—the ability to learn and adjust continuously. In tutorial, you'll conduct mini-experiments with AI for career preparation tasks. Some will work brilliantly. Some will fail. The goal isn't perfection; it's developing the habit of experimentation and reflection. That habit will serve you throughout your career as AI capabilities continue to evolve.
</speaker-notes>
</slide>

---

<slide number="20" layout="content" title="Key Takeaway: Human Judgment">
**What You Should Remember:**

1. **"Human in the loop" is insufficient**—you must be "human at the helm" demonstrating judgment
2. **Pilot vs. Passenger mindset** determines career outcomes:
   - Pilots use AI as thought partner
   - Passengers use AI as answer generator
3. **Judgment addresses questions AI cannot:**
   - Strategic alignment, ethical implications, cultural context, relationship dynamics
4. **Develop the "Chief Experimentation Officer" mindset:**
   - Continuous testing, systematic reflection, learning from failure

**Immediate Action:** Next time you use AI, pause before accepting its output. Ask: "Does this reflect MY judgment and strategic thinking, or am I just accepting what AI produced?"

<speaker-notes>
Judgment is not innate—it's developed through practice and reflection. The executives we quoted aren't asking for superhuman abilities; they're asking for thoughtful, reflective AI use where humans take responsibility for strategic decisions. The pilot vs. passenger framework gives you a clear mental model: every time you work with AI, you're choosing which mindset to adopt. Choose pilot. The Chief Experimentation Officer approach gives you a methodology: treat every AI interaction as an experiment to learn from. Over time, these experiments compound into genuine expertise.
</speaker-notes>
</slide>

---

<slide number="21" layout="section-break" title="Part 3: The Workslop Problem">
Part 3

The Hidden Risk:
AI-Generated "Workslop" and Professional Reputation

<speaker-notes>
We've covered the premium skill (context engineering) and the strategic capability (judgment). Now we address the career-destroying risk: workslop. This term, coined by Stanford and BetterUp Labs researchers in September 2025, describes AI-generated content that appears polished superficially but lacks substance. Understanding workslop is critical because: (1) you will encounter it constantly in professional settings, (2) you risk creating it if you adopt the passenger mindset, and (3) your professional reputation depends on avoiding it. Let's explore what workslop is, why it's spreading, and how to protect yourself.
</speaker-notes>
</slide>

---

<slide number="22" layout="content" title="What Is Workslop?">
**Definition (Stanford + BetterUp Labs, September 2025):**
AI-generated content that appears polished but lacks substantive insights, strategic thinking, or authentic human judgment.

**You've Experienced Workslop If:**
- You opened a document that looked professional but left you confused about the main point
- You read an email that used many words to say very little
- You received a report with impressive formatting but no actionable recommendations

**The Hidden Epidemic:**
- **41% of workers** have encountered workslop from colleagues
- **53% felt annoyed** when they received workslop
- **22% felt offended** that someone wasted their time
- **50% view workslop senders as less capable professionals**

<speaker-notes>
The term "workslop" is brilliant because it captures both the problem and the tone. It combines "work" with "slop"—work that's been carelessly thrown together. The research findings are sobering: nearly half of workers have already encountered workslop, and reactions are overwhelmingly negative. This matters for your career because professional reputation is built slowly and destroyed quickly. If you develop a reputation as someone who produces workslop, colleagues will stop trusting your judgment, managers will stop assigning you important work, and your career advancement will stall. The statistics show that workslop damages relationships—53% annoyed, 22% offended. In Vietnamese business culture, where harmony and respect are paramount, offending colleagues by wasting their time with hollow work is particularly damaging.
</speaker-notes>
</slide>

---

<slide number="23" layout="content" title="The Productivity Paradox: Why AI Often Increases Workload">
**The Promise vs. The Reality**

**The Promise:** AI will save time and boost productivity

**The Reality (2025 Data):**
- **95% of AI projects** fail to show positive ROI (MIT Media Lab)
- **~2 hours of rework** per workslop incident
- **$186/month** invisible productivity tax per worker who regularly receives workslop
- Workers spend time deciphering, questioning, and correcting AI-generated content

**Why This Happens:**
When people use AI as a shortcut rather than a thought partner, they create work that looks complete but requires extensive rework by others.

**The Asana Paradox (2025):** 90% of highly productive workers report AI creates MORE coordination work initially.

<speaker-notes>
This is perhaps the most surprising finding from 2025 research: despite AI's impressive capabilities, 95% of AI projects fail to deliver positive return on investment. Why? Because people are producing workslop. When you send a colleague an AI-generated report that lacks strategic insight, they must spend 2 hours figuring out what you actually meant, what's missing, and what needs correction. That's 2 hours ADDED to the system, not saved. The $186/month figure comes from quantifying these invisible costs across organizations. The Asana finding about highly productive workers is equally important: even skilled users find that AI initially increases coordination work because you must verify outputs, align on standards, and correct misconceptions. The productivity gains come LATER, after you've developed expertise. This is why the pilot mindset is essential—pilots invest time upfront ensuring quality, preventing downstream rework.
</speaker-notes>
</slide>

---

<slide number="24" layout="framework" title="Framework 5: The 30-Second Test">
**Before Submitting ANY AI-Assisted Work, Ask:**

"Would a colleague reviewing this for 30 seconds recognize it as thoughtful human work or AI-generated filler?"

**Red Flags That Indicate Workslop:**
1. **Generic phrasing**: "It's important to note that...", "In today's fast-paced business environment..."
2. **Lack of specifics**: Broad statements without concrete examples or data
3. **No clear argument**: Points are listed but not connected to a strategic conclusion
4. **Missing context**: Assumes reader has background knowledge they may not have
5. **Surface-level analysis**: Identifies obvious points without deeper insight

**Green Flags That Indicate Thoughtful Work:**
1. **Specific examples** tied to YOUR context
2. **Clear strategic recommendation** with reasoning
3. **Acknowledgment of tradeoffs** and alternative perspectives
4. **Evidence of domain knowledge** that AI couldn't have without your input

<speaker-notes>
The 30-Second Test is your quality control tool. Imagine a busy colleague opening your document while waiting for a meeting to start. In 30 seconds, can they grasp your main point and recognize you've done thoughtful work? Or does it read like an AI essay? The red flags are telltale signs of workslop. Generic phrasing like "In today's fast-paced business environment" is what AI produces when it lacks specific context—it's verbal filler. Lack of specifics means you didn't provide AI with rich context (context engineering failure) or didn't add details yourself (passenger mindset). No clear argument means you accepted AI's structure without applying judgment. The green flags indicate pilot mindset: specific examples come from YOUR curation, strategic recommendations require YOUR judgment, acknowledgment of tradeoffs shows YOUR critical thinking, domain knowledge proves YOU guided the AI. Use this test on every piece of work before submission.
</speaker-notes>
</slide>

---

<slide number="25" layout="content" title="Workslop in Job Applications: The Career Risk">
**Sobering Statistics from 2025 Research:**

- **1 in 10 job seekers** were denied positions when employers discovered AI use in application materials
- Recruiters can increasingly detect AI-generated cover letters
- Employers are developing "authenticity screening" processes

**What Went Wrong:**
- Generic cover letters that could apply to any company
- CVs restructured by AI without strategic personalization
- Interview answers that sound rehearsed and lack genuine reflection

**The Paradox:**
- AI can help you prepare application materials
- But AI-generated materials that lack YOUR authentic voice and judgment will get rejected

**Solution:** Use AI as thought partner (pilot) not answer generator (passenger)

<speaker-notes>
This is the highest-stakes application of workslop awareness: your career entry depends on it. The 1-in-10 statistic is conservative—many recruiters are rejecting AI-detected applications without telling candidates why. What triggers detection? Generic phrasing, lack of specific company knowledge, answers that sound like they came from a template. Here's the key insight: AI can absolutely help you prepare strong application materials, but only if YOU provide rich context (the specific company culture, your authentic experiences, your genuine interest) and YOU exercise judgment about what to emphasize. If you paste a job description into AI and ask for a cover letter, you'll get workslop. If you analyze what the company needs, identify your relevant experiences, and ask AI to help you articulate connections, you'll get quality material. Tutorial will give you extensive practice distinguishing these approaches.
</speaker-notes>
</slide>

---

<slide number="26" layout="quote" title="The Cost of Carelessness">
"You might recall the feeling of confusion after opening such a document, followed by frustration. You might have had to spend hours on something that should have taken just one, or found yourself in meetings that could have been avoided."

— Stanford + BetterUp Labs Research
Harvard Business Review, September 2025

<speaker-notes>
This quote captures the emotional reality of receiving workslop. It's not just inefficiency—it's confusion, frustration, wasted time, and damaged relationships. When you send someone workslop, you're communicating: "I didn't respect your time enough to ensure this was actually useful." In Vietnamese business culture, this violates fundamental norms of respect and conscientiousness. The researchers note that recipients of workslop often must schedule unnecessary meetings to clarify what should have been clear in writing—meetings that waste multiple people's time. The opportunity cost is enormous: those hours could have been spent on strategic work, but instead they're spent deciphering unclear communications. Your professional brand is built on reliability and quality. One instance of workslop might be forgiven. Repeated instances will define your reputation.
</speaker-notes>
</slide>

---

<slide number="27" layout="content" title="Key Takeaway: Avoiding Workslop">
**What You Should Remember:**

1. **Workslop is AI-generated content that looks polished but lacks substance**—and it destroys professional credibility
2. **The statistics are damning:**
   - 41% of workers have encountered workslop
   - 50% view workslop creators as less capable
   - 1 in 10 job seekers rejected when AI use detected
3. **Use the 30-Second Test** before submitting any AI-assisted work
4. **AI amplifies your thinking—or reveals its absence**:
   - Pilot mindset → AI helps you articulate strategic insights
   - Passenger mindset → AI generates hollow filler

**Immediate Action:** Review something you created with AI assistance. Does it pass the 30-Second Test? If not, what would you add to demonstrate YOUR judgment?

<speaker-notes>
Workslop awareness is about protecting your professional reputation in an AI era. The good news: it's completely avoidable by adopting the pilot mindset and applying the 30-Second Test. The bad news: most people will fail to do this, creating opportunities for those who do. Your competitive advantage comes from consistently producing work that demonstrates judgment, strategic thinking, and authentic human insight—work that AI assisted but didn't create. In the next segment, we'll explore a practical framework for using AI in career preparation that avoids the workslop trap.
</speaker-notes>
</slide>

---

<slide number="28" layout="section-break" title="Part 4: Practical Career Framework">
Part 4

The Practical Framework:
AI-Assisted Career Preparation Done Right

<speaker-notes>
We've built the foundation: context engineering (the technical skill), judgment (the strategic capability), and workslop awareness (the critical risk). Now we conclude with immediately actionable frameworks for using AI in your career preparation. This segment draws on research from Inside Higher Ed (October 2025) specifically focused on how graduate students should use GenAI for career development. The frameworks apply perfectly to your situation as business undergraduates preparing to enter the job market.
</speaker-notes>
</slide>

---

<slide number="29" layout="framework" title="Framework 6: Explore-Build-Connect-Refine">
**A Four-Stage Approach to AI-Assisted Career Development**

**Stage 1: EXPLORE—Map possibilities and surface gaps**
- Use AI to infer competencies from coursework
- Compare your skills against job postings
- Identify scholarship/fellowship opportunities
- Understand communication norms in target industries

**Stage 2: BUILD—Learn through iterative practice**
- Experiment with CV architectures (chronological vs. skills-based)
- Create mock interview questions
- Generate individual development plans
- Overcome "blank-page intimidation" in writing

**Stage 3: CONNECT—Communicate and network with purpose**
- Rehearse elevator pitches with AI roleplaying different audiences
- Simulate informational interviews
- Draft outreach messages for personalization
- Explore networking strategies

**Stage 4: REFINE—Test, adapt, and verify**
- Simulate reviewer critiques
- A/B test narrative approaches
- Identify jargon and unclear transitions
- **CRITICAL:** Verify all references, deadlines, and claims against primary sources

<speaker-notes>
This framework, developed by career services professionals at U.S. universities, provides a systematic approach to AI-assisted career preparation. Notice the progression: Explore is about discovery and self-assessment; Build is about skill development through practice; Connect is about relationship-building and communication; Refine is about quality control and verification. Each stage involves AI as a thought partner—AI helps you explore options you might not have considered, provides feedback on practice attempts, simulates conversation partners, and identifies weaknesses. But YOU remain at the helm throughout. YOU decide which opportunities to pursue (Explore), YOU evaluate which practice approaches work best (Build), YOU personalize networking messages (Connect), and YOU verify accuracy (Refine). This is the pilot mindset operationalized.
</speaker-notes>
</slide>

---

<slide number="30" layout="content" title="Stage 1: EXPLORE—Practical Applications">
**How to Use AI for Career Exploration**

**Skill Mapping Exercise:**
"I'm majoring in Business Administration with coursework in [list courses]. Based on these, what professional competencies have I likely developed? Where might I have gaps compared to typical marketing analyst positions?"

**Industry Research:**
"What are the communication norms in Vietnam's fintech industry? How do professionals typically network and build relationships? What are unwritten expectations I should know?"

**Opportunity Identification:**
"Based on my interest in [field] and my background in [skills], what graduate programs, fellowships, or professional development opportunities might be good fits? What criteria should I prioritize?"

**Key Principle:** You're using AI to surface options and insights you might miss, not to make decisions for you.

<speaker-notes>
Stage 1 (Explore) is about expanding your awareness. AI can help you identify skills you've developed through coursework that you might not articulate clearly on your own. It can research industry norms you'd need hours to discover. It can suggest opportunities you didn't know existed. But notice: these are all INPUTS to your decision-making, not outputs. AI might tell you that marketing analyst roles require SQL skills and you have a gap—but YOU must decide whether to develop SQL skills, pursue different roles, or emphasize other strengths. This stage demonstrates context engineering: the more specific context you provide (courses taken, career interests, constraints), the more valuable AI's exploration becomes. Generic request = generic response. Rich context = strategic insights.
</speaker-notes>
</slide>

---

<slide number="31" layout="content" title="Stage 2: BUILD—Practical Applications">
**How to Use AI for Skill Development**

**CV Architecture Testing:**
"Here are my experiences [list]. Help me experiment with two versions: (1) chronological format emphasizing career progression, (2) skills-based format emphasizing data analysis capabilities. What are the tradeoffs of each?"

**Mock Interview Practice:**
"I'm interviewing for [role] at [company]. Generate 10 behavioral interview questions specific to this role. After I answer each, provide feedback on structure and content."

**Overcoming Writer's Block:**
"I need to write a cover letter explaining why I'm interested in [company]. Here's what I know: [context]. Help me brainstorm 5 different opening angles I could take."

**Key Principle:** You're using AI for iterative practice and feedback, not for generating final deliverables.

<speaker-notes>
Stage 2 (Build) is where you develop skills through practice. Notice how different this is from the passenger approach. A passenger asks AI to write the cover letter. A pilot asks AI to help EXPLORE different approaches, then the pilot WRITES the letter incorporating insights from that exploration. The mock interview example is particularly powerful—you can practice answering questions, receive feedback, and iterate multiple times before the real interview. This is the Chief Experimentation Officer mindset in action. Each practice session is an experiment; you learn from what works and adjust. The blank-page intimidation point is important: AI can help you START writing by brainstorming angles, but YOU must do the actual writing. AI provides scaffolding; you provide substance.
</speaker-notes>
</slide>

---

<slide number="32" layout="content" title="Stage 3: CONNECT—Practical Applications">
**How to Use AI for Networking and Communication**

**Elevator Pitch Practice:**
"I need a 60-second elevator pitch for [context: career fair, networking event, informational interview]. Here's my background: [details]. Help me craft a pitch, then roleplay as [target audience] and ask follow-up questions."

**Informational Interview Simulation:**
"Simulate an informational interview where I'm asking [professional] about their career path in [industry]. Ask me to introduce myself and share my career interests, then respond as they might."

**Outreach Message Drafting:**
"I want to connect with [person] at [company] to learn about [topic]. Here's why I'm interested: [authentic reason]. Help me draft an initial message that I can personalize before sending."

**Key Principle:** AI helps you rehearse and refine, but the actual connections must be authentic and human.

<speaker-notes>
Stage 3 (Connect) focuses on relationship-building—arguably the most important career skill in Vietnamese business culture. Here's the critical distinction: AI can help you PRACTICE communication, but it cannot REPLACE authentic human connection. Using AI to roleplay an informational interview is brilliant preparation. Using AI to generate networking messages that you send without personalization is relationship suicide—people can tell, and you'll be remembered negatively. The framework here is clear: AI for rehearsal and refinement, humans for actual connection. Notice how this integrates Week 1's emotional intelligence skill: you must read the relationship, adapt to context, and communicate authentically. AI can't do that for you, but it can help you prepare so you're more confident and articulate when the human moment arrives.
</speaker-notes>
</slide>

---

<slide number="33" layout="content" title="Stage 4: REFINE—Practical Applications">
**How to Use AI for Quality Control**

**Critique Simulation:**
"Review this cover letter as if you're a hiring manager looking for reasons to reject it. Be harsh. What weaknesses do you see?"

**A/B Testing Narratives:**
"Here are two ways I could explain my career transition from [X] to [Y]. Which is more compelling, and why? What would make the weaker version stronger?"

**Jargon Detection:**
"Read this draft and identify any business jargon, unclear transitions, or places where I assume knowledge the reader might not have."

**CRITICAL VERIFICATION STEP:**
"I'm about to submit this application. Help me verify: Are there any claims I haven't substantiated? Any dates or facts I should double-check? Any company-specific details I should confirm?"

**Key Principle:** AI assists quality control, but YOU are responsible for accuracy and authenticity.

<speaker-notes>
Stage 4 (Refine) is where workslop gets prevented. The critique simulation is powerful because AI can be brutally honest without hurting your feelings—use this to strengthen your work before human reviewers see it. A/B testing lets you compare different approaches systematically. Jargon detection helps ensure clarity. But the verification step is CRITICAL and cannot be skipped. AI hallucinates—it will occasionally cite scholarships that don't exist, claim companies have programs they don't offer, or misstate deadlines. YOU must verify every factual claim against primary sources. This is non-negotiable. In tutorial, you'll practice this entire four-stage framework on your own career materials. By the end of tutorial, you'll have draft application materials that demonstrate pilot mindset, context engineering, and workslop-free quality.
</speaker-notes>
</slide>

---

<slide number="34" layout="content" title="What Employers Actually Want: NACE 2025 Data">
**National Association of Colleges and Employers (NACE) 2025 Survey**

**Top 5 Competencies Employers Seek:**
1. **Communication** (91% of employers rate this as essential)
2. **Critical Thinking** (86%)
3. **Teamwork** (82%)
4. **Professionalism** (81%)
5. **Adaptability** (78%)

**Key Insight:**
These are exactly the skills developed when you use AI as a THOUGHT PARTNER rather than an ANSWER GENERATOR.

**The Connection:**
- Context engineering → Critical Thinking
- Pilot mindset → Professionalism
- Judgment integration → Communication & Teamwork
- Chief Experimentation Officer → Adaptability
- Workslop awareness → Professionalism

<speaker-notes>
This is perhaps the most reassuring data for students worried about AI displacing human workers. Employers don't primarily want technical AI skills—they want communication, critical thinking, teamwork, professionalism, and adaptability. These are fundamentally human capabilities that AI cannot replicate. But here's the key insight: these are exactly the skills you develop BY USING AI EFFECTIVELY. When you practice context engineering, you're exercising critical thinking—deciding what information matters and why. When you adopt pilot mindset, you're demonstrating professionalism—taking responsibility for quality. When you integrate judgment, you're developing communication skills—articulating the "why" behind decisions. The Chief Experimentation Officer approach builds adaptability through continuous learning. And workslop awareness ensures professionalism. So the path forward is clear: don't fear AI, and don't try to compete with AI at data processing. Instead, use AI to develop the human capabilities employers actually value.
</speaker-notes>
</slide>

---

<slide number="35" layout="content" title="Key Takeaway: Practical Career Framework">
**What You Should Remember:**

1. **Use the Explore-Build-Connect-Refine framework** for systematic AI-assisted career development
2. **Each stage has a different purpose:**
   - Explore: Discovery and self-assessment
   - Build: Skill development through practice
   - Connect: Relationship-building and communication
   - Refine: Quality control and verification
3. **AI is your thought partner, not your answer generator**
4. **Always verify factual claims** against primary sources—AI hallucinates
5. **Employers want human skills** (communication, critical thinking, teamwork)—develop these BY using AI effectively

**In Tutorial:** You'll apply this entire framework to create your own career preparation materials using AI assistance.

<speaker-notes>
This framework ties together everything we've covered today. Context engineering makes each stage more effective. Judgment determines how to interpret AI's suggestions. Workslop awareness ensures quality throughout. And the NACE data shows that developing these capabilities is exactly what employers want. In tutorial, you'll work through all four stages with real career preparation tasks. This is where theoretical knowledge becomes practical skill.
</speaker-notes>
</slide>

---

<slide number="36" layout="content" title="Synthesis: How Week 1 and Week 2 Connect">
**Week 1: The Five Future Skills Foundation**
- Critical Thinking
- Creativity
- Emotional Intelligence
- Adaptability
- Communication

**Week 2: Operationalizing Those Skills in the AI Era**
- Critical Thinking → Context Engineering (deciding what information matters)
- Creativity → Pilot Mindset (using AI to amplify, not replace, creative thinking)
- Emotional Intelligence → Judgment Integration (considering factors AI can't quantify)
- Adaptability → Chief Experimentation Officer (continuous learning and iteration)
- Communication → Workslop Awareness (ensuring messages are clear and substantive)

**The Progression:**
Week 1 established WHAT skills matter.
Week 2 established HOW to develop and apply those skills when AI is your collaborator.

<speaker-notes>
This synthesis is critical for students to see that Week 1 and Week 2 aren't separate topics—they're a coherent progression. The five future skills we established in Week 1 are not abstract aspirations; they're the foundation for effective AI collaboration. Context engineering is critical thinking applied to AI interaction. The pilot mindset requires creativity to see possibilities beyond AI's initial outputs. Judgment integration requires emotional intelligence to consider human factors AI cannot quantify. The Chief Experimentation Officer mindset is adaptability operationalized. And workslop awareness is communication skill applied to AI-assisted work. Everything connects. Students who master both weeks will have a significant competitive advantage: they know what skills matter AND how to develop them in an AI-augmented environment.
</speaker-notes>
</slide>

---

<slide number="37" layout="content" title="Looking Ahead: Week 3 Preview">
**Next Week: Collaboration & Teamwork**

**Building on Today:**
- You've learned to collaborate effectively with AI (pilot mindset)
- Next week: Collaborating effectively with HUMANS in AI-augmented teams
- Key questions we'll explore:
  - How does AI change team dynamics?
  - What coordination challenges arise when team members use AI differently?
  - How do you build trust when some team members are "pilots" and others are "passengers"?

**Connection to Assessment:**
Your Week 4 Personal Future Skills Plan should address BOTH:
- How you'll use AI to develop skills (today's frameworks)
- How you'll collaborate with others in AI-augmented environments (next week's focus)

<speaker-notes>
Week 3 builds logically on Week 2. Now that you understand effective individual AI use, we'll explore the complexities of team-level AI use. This matters because you'll rarely work alone—you'll be on teams where different members have different AI capabilities and mindsets. How do you coordinate when one colleague produces workslop while another is an effective pilot? How do you build shared team standards? These are the questions Week 3 addresses. For your Assessment 1, this means your Personal Future Skills Plan should demonstrate understanding of BOTH individual skill development (Week 2 focus) AND collaborative effectiveness (Week 3 focus). We're building a comprehensive framework for thriving in AI-augmented workplaces.
</speaker-notes>
</slide>

---

<slide number="38" layout="content" title="Key Takeaways: Week 2 Summary">
**Six Frameworks from Today:**

1. **Context Engineering**: Goldilocks Zone + Minimum Effective Dose + Attention Budget
2. **Judgment Integration**: Moving from "human in the loop" to "human at the helm"
3. **Pilot vs. Passenger**: Using AI as thought partner vs. answer generator
4. **The 30-Second Test**: Quality control for avoiding workslop
5. **Explore-Build-Connect-Refine**: Systematic framework for AI-assisted career preparation
6. **Chief Experimentation Officer**: Continuous learning through systematic experimentation

**Your Competitive Advantage:**
Most people will use AI carelessly, producing workslop and damaging their professional reputation.
YOU now have frameworks to use AI strategically, demonstrating judgment and building career capital.

<speaker-notes>
These six frameworks are your toolkit for effective AI collaboration. Memorizing them is less important than USING them. Starting today, every time you interact with AI, apply these frameworks: Am I providing good context (Goldilocks, Minimum Effective Dose, Attention Budget)? Am I exercising judgment or just accepting outputs? Am I being a pilot or passenger? Would this pass the 30-Second Test? Which stage of Explore-Build-Connect-Refine am I in? Am I approaching this experimentally? These questions become second nature with practice. The competitive advantage is real: research shows most people will NOT adopt these practices, creating opportunities for those who do.
</speaker-notes>
</slide>

---

<slide number="39" layout="content" title="Action Steps Before Next Class">
**1. Complete the Required Readings (listed on final slide)**
- Focus on understanding frameworks, not memorizing details
- Annotate examples that resonate with your career goals

**2. Prepare for Tutorial**
- Bring a job description for a role you might pursue after graduation
- Bring your current CV (or draft if you don't have one yet)
- Be ready to practice AI-assisted career preparation

**3. Self-Assessment Reflection**
- Think about your recent AI use: Have you been more pilot or passenger?
- Identify one area where you could improve context engineering
- Consider: What judgment calls have you made recently that AI couldn't make for you?

**4. Begin Thinking About Assessment 1**
- Your Personal Future Skills Plan (due Week 4)
- Today's frameworks will be essential for demonstrating strategic thinking

<speaker-notes>
These action steps prepare you for tutorial and begin scaffolding Assessment 1. The readings reinforce today's frameworks with detailed examples and research. The tutorial preparation ensures you can practice immediately with real materials. The self-assessment reflection develops metacognitive awareness—thinking about HOW you think and work. And beginning to consider Assessment 1 ensures you're not surprised by the requirements when the deadline approaches. In tutorial, you'll have hands-on practice applying every framework from today. Come prepared to experiment, make mistakes, and learn.
</speaker-notes>
</slide>

---

<slide number="40" layout="content" title="Questions for Reflection">
**Discuss with a classmate or reflect individually:**

1. **Context Engineering**: Think of a recent time you used AI. What context did you provide? What context did you omit? How might better context engineering have improved the result?

2. **Judgment**: Describe a decision you made recently that AI couldn't make for you. What human factors did you consider?

3. **Workslop**: Have you encountered work (from others or yourself) that looked polished but lacked substance? What made it hollow?

4. **Career Preparation**: Which stage of Explore-Build-Connect-Refine feels most challenging to you, and why?

5. **Mindset**: When do you find yourself slipping into "passenger" mode, and what triggers could help you shift to "pilot" mode?

<speaker-notes>
These reflection questions are designed for active processing. If time permits, have students discuss in pairs for 3-4 minutes. The questions move from concrete (recent AI use) to abstract (mindset awareness) to forward-looking (career preparation). The goal is to help students connect frameworks to their own experiences. The workslop question is particularly valuable—students often recognize it immediately when named, even if they couldn't articulate the problem before. The mindset question about "passenger triggers" helps students develop self-awareness: when are you most likely to use AI carelessly, and how can you catch yourself? This metacognitive awareness is the foundation of the Chief Experimentation Officer mindset.
</speaker-notes>
</slide>

---

<slide number="41" layout="references" title="References">
**Required Readings:**

Chremos, I. V., & Repetto, W. A. (2025, October 20). Framework for GenAI in graduate career development. *Inside Higher Ed*. https://www.insidehighered.com/opinion/career-advice/carpe-careers/2025/10/20/framework-genai-graduate-career-development-opinion

Fortune Staff. (2025, October 14). As AI fears continue, executives say a human in the loop is not enough—workers need to prioritize one skill. *Fortune*. https://fortune.com/2025/10/14/artifical-intelligence-fears-human-in-the-loop-not-enough-need-proper-judgement-business-success-microsoft-workday-guild-executives/

Niederhoffer, K., Rosen Kellerman, G., Lee, A., Liebscher, A., Rapuano, K., & Hancock, J. T. (2025, September 22). AI-generated "workslop" is destroying productivity. *Harvard Business Review*. https://hbr.org/2025/09/ai-generated-workslop-is-destroying-productivity

Rajasekaran, P., Dixon, E., Ryan, C., & Hadfield, J. (2025, September 29). Effective context engineering for AI agents. *Anthropic Engineering Blog*. https://www.anthropic.com/engineering/effective-context-engineering-for-ai-agents

<speaker-notes>
All four required readings are current (June-October 2025), open access or require free registration only, and directly applicable to your career preparation. The Rajasekaran article from Anthropic provides the technical foundation for context engineering. The Fortune article captures executive perspectives on judgment. The HBR article on workslop provides essential risk awareness. And the Inside Higher Ed article gives you step-by-step career preparation guidance. Together, these readings form a comprehensive foundation for thriving in AI-augmented careers. Read them in the suggested sequence: Fortune for strategic context, HBR for risk awareness, Anthropic for technical skill, Inside Higher Ed for practical application.
</speaker-notes>
</slide>

